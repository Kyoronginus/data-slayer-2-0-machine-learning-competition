{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10173406,"sourceType":"datasetVersion","datasetId":6283444},{"sourceId":10193603,"sourceType":"datasetVersion","datasetId":6298432},{"sourceId":10198298,"sourceType":"datasetVersion","datasetId":6301602},{"sourceId":10200494,"sourceType":"datasetVersion","datasetId":6303304},{"sourceId":10201824,"sourceType":"datasetVersion","datasetId":6304343},{"sourceId":10203994,"sourceType":"datasetVersion","datasetId":6305780},{"sourceId":10208241,"sourceType":"datasetVersion","datasetId":6308929}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics torch opencv-python scikit-learn pyyaml xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:35:32.376681Z","iopub.execute_input":"2024-12-16T13:35:32.377024Z","iopub.status.idle":"2024-12-16T13:35:46.382405Z","shell.execute_reply.started":"2024-12-16T13:35:32.376987Z","shell.execute_reply":"2024-12-16T13:35:46.381511Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.50-py3-none-any.whl (898 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.0/899.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (4.10.0.84)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (1.5.2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (6.0.2)\nCollecting xgboost\n  Downloading xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from ultralytics) (6.1.0)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (0.13.2)\nCollecting ultralytics-thop>=2.0.0\n  Downloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (3.9.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/site-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nCollecting py-cpuinfo\n  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/site-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch) (11.0.2.54)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch) (2.20.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/site-packages (from torch) (3.0.0)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.3.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch) (2024.10.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch) (3.16.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nInstalling collected packages: py-cpuinfo, xgboost, ultralytics-thop, ultralytics\nSuccessfully installed py-cpuinfo-9.0.0 ultralytics-8.3.50 ultralytics-thop-2.0.13 xgboost-2.1.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(\"GPU Available:\", torch.cuda.is_available())\nprint(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:35:46.384107Z","iopub.execute_input":"2024-12-16T13:35:46.384404Z","iopub.status.idle":"2024-12-16T13:36:05.793096Z","shell.execute_reply.started":"2024-12-16T13:35:46.384368Z","shell.execute_reply":"2024-12-16T13:36:05.792103Z"}},"outputs":[{"name":"stdout","text":"GPU Available: False\nGPU Name: No GPU detected\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport yaml\nimport torch\nfrom ultralytics import YOLO\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport cv2\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:36:05.794243Z","iopub.execute_input":"2024-12-16T13:36:05.794593Z","iopub.status.idle":"2024-12-16T13:36:11.454182Z","shell.execute_reply.started":"2024-12-16T13:36:05.794564Z","shell.execute_reply":"2024-12-16T13:36:11.453021Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n\ndef load_data(root_dir):\n    \"\"\"\n    Load data from the specified root directory\n    \n    Args:\n        root_dir (str): Root directory containing subject folders\n    \n    Returns:\n        tuple: Lists of image paths and corresponding labels\n    \"\"\"\n    data = []\n    labels = []\n    for subject in os.listdir(root_dir):\n        subject_path = os.path.join(root_dir, subject)\n        if os.path.isdir(subject_path):  # Check if it's a directory\n            for activity_type in os.listdir(subject_path):\n                activity_path = os.path.join(subject_path, activity_type)\n                if os.path.isdir(activity_path):  # Check if it's a directory\n                    label = 1 if activity_type == 'fall' else 0\n                    for activity_class in os.listdir(activity_path):\n                        class_path = os.path.join(activity_path, activity_class)\n                        if os.path.isdir(class_path):  # Check if it's a directory\n                            for file in os.listdir(class_path):\n                                file_path = os.path.join(class_path, file)\n                                if os.path.isfile(file_path):  # Ensure it's a file\n                                    data.append(file_path)\n                                    labels.append(label)\n    return data, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:36:11.456415Z","iopub.execute_input":"2024-12-16T13:36:11.456925Z","iopub.status.idle":"2024-12-16T13:36:11.464226Z","shell.execute_reply.started":"2024-12-16T13:36:11.456890Z","shell.execute_reply":"2024-12-16T13:36:11.463299Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_data, train_labels = load_data(\"/kaggle/input/dataslayerdatasets/train\")\nprint(f\"Total images loaded: {len(train_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:36:11.465270Z","iopub.execute_input":"2024-12-16T13:36:11.465522Z","iopub.status.idle":"2024-12-16T13:36:12.651521Z","shell.execute_reply.started":"2024-12-16T13:36:11.465488Z","shell.execute_reply":"2024-12-16T13:36:12.650615Z"}},"outputs":[{"name":"stdout","text":"Total images loaded: 4294\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import csv\nimport os\nimport shutil\nfrom ultralytics import YOLO\nimport tensorflow as tf\n\n# Create a directory for YOLO predictions\nyolo_input_dir = \"/kaggle/working/yolo_input\"\nos.makedirs(yolo_input_dir, exist_ok=True)\n\n# Copy images into YOLO input directory with unique filenames and validation\nfor img_path in train_data:\n    if os.path.exists(img_path) and os.path.isfile(img_path):\n        # Create a unique filename to prevent overwriting\n        unique_filename = \"_\".join(img_path.split(os.sep)[-3:])  # Use parent folders + filename\n        unique_filepath = os.path.join(yolo_input_dir, unique_filename)\n        shutil.copy(img_path, unique_filepath)\n    else:\n        print(f\"File not found or inaccessible: {img_path}\")\n\n# Verify the total number of files copied\ncopied_files = os.listdir(yolo_input_dir)\nprint(f\"Total files copied to YOLO input directory: {len(copied_files)}\")\n\n\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\n# instantiate a distribution strategy\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    \n    \n    # Initialize YOLOv8n-pose model\n    model = YOLO('yolov8n-pose.pt')\n    \n    # Run predictions on the copied images\n    results = model.predict(\n        source=yolo_input_dir,  # Directory containing images\n        task=\"pose\",\n        imgsz=640,\n        verbose=False,\n        save=True  # Save predictions\n    )\n    \n    # Output directory for saved results\n    print(f\"Predictions saved in: {results[0].save_dir}\")\n    \n    # train model normally\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:36:12.652718Z","iopub.execute_input":"2024-12-16T13:36:12.653023Z","iopub.status.idle":"2024-12-16T13:40:49.878572Z","shell.execute_reply.started":"2024-12-16T13:36:12.652996Z","shell.execute_reply":"2024-12-16T13:40:49.877673Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1734356178.291897      13 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD1216 13:36:18.301716056      13 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD1216 13:36:18.301735086      13 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD1216 13:36:18.301738914      13 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD1216 13:36:18.301741424      13 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD1216 13:36:18.301743871      13 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD1216 13:36:18.301746300      13 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD1216 13:36:18.301748716      13 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD1216 13:36:18.301751014      13 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD1216 13:36:18.301777037      13 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD1216 13:36:18.301782596      13 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD1216 13:36:18.301787759      13 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD1216 13:36:18.301791502      13 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD1216 13:36:18.301796998      13 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD1216 13:36:18.301800023      13 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD1216 13:36:18.301802457      13 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD1216 13:36:18.301804821      13 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD1216 13:36:18.301807267      13 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD1216 13:36:18.301809613      13 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD1216 13:36:18.301811883      13 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD1216 13:36:18.301814197      13 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD1216 13:36:18.301816494      13 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD1216 13:36:18.301818773      13 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD1216 13:36:18.301821152      13 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD1216 13:36:18.301823509      13 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD1216 13:36:18.301825731      13 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD1216 13:36:18.301827948      13 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD1216 13:36:18.301830263      13 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD1216 13:36:18.301832561      13 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD1216 13:36:18.301834945      13 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD1216 13:36:18.301838973      13 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD1216 13:36:18.301841410      13 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD1216 13:36:18.301843811      13 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD1216 13:36:18.301846251      13 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD1216 13:36:18.301848583      13 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD1216 13:36:18.301850885      13 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD1216 13:36:18.301853170      13 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD1216 13:36:18.301855386      13 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD1216 13:36:18.301857656      13 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD1216 13:36:18.301860011      13 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD1216 13:36:18.301862331      13 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD1216 13:36:18.301864641      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD1216 13:36:18.301866889      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD1216 13:36:18.301869191      13 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD1216 13:36:18.301871543      13 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD1216 13:36:18.301874043      13 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI1216 13:36:18.302099220      13 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD1216 13:36:18.302112500      13 ev_posix.cc:113]                      Using polling engine: epoll1\nD1216 13:36:18.313768631      13 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1216 13:36:18.313782111      13 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1216 13:36:18.313808266      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1216 13:36:18.313812844      13 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1216 13:36:18.313816326      13 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1216 13:36:18.313819629      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD1216 13:36:18.313850215      13 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1216 13:36:18.313863838      13 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD1216 13:36:18.313881658      13 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1216 13:36:18.313908010      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1216 13:36:18.313917012      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1216 13:36:18.313920685      13 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1216 13:36:18.313925856      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1216 13:36:18.313929328      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1216 13:36:18.313932605      13 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1216 13:36:18.313936728      13 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD1216 13:36:18.313968758      13 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI1216 13:36:18.315886786      13 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI1216 13:36:18.325645086      13 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI1216 13:36:18.328922281     119 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI1216 13:36:18.328980770     119 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1216 13:36:18.334604554      13 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-12-16T13:36:18.33458802+00:00\", grpc_status:2}\n","output_type":"stream"},{"name":"stdout","text":"Total files copied to YOLO input directory: 4294\nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734356207.948698      13 service.cc:145] XLA service 0x5a53d5e0fdb0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734356207.948818      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1734356207.948827      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1734356207.948834      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1734356207.948840      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1734356207.948847      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1734356207.948854      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1734356207.948860      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1734356207.948867      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.52M/6.52M [00:00<00:00, 181MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\nWARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\nerrors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n\nExample:\n    results = model(source=..., stream=True)  # generator of Results objects\n    for r in results:\n        boxes = r.boxes  # Boxes object for bbox outputs\n        masks = r.masks  # Masks object for segment masks outputs\n        probs = r.probs  # Class probabilities for classification outputs\n\nResults saved to \u001b[1mruns/pose/predict\u001b[0m\nPredictions saved in: runs/pose/predict\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import csv\nimport os\nimport numpy as np\n\n# Define the output CSV path\noutput_csv = \"/kaggle/working/yolo_keypoints.csv\"\n\n# Open the CSV file for writing\nwith open(output_csv, mode='w', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    \n    # Write the CSV header\n    # Header: image_name, keypoint_1_x, keypoint_1_y, ..., keypoint_17_x, keypoint_17_y\n    header = ['image_name']\n    for i in range(1, 18):  # Assuming 17 keypoints for pose\n        header.extend([f'keypoint_{i}_x', f'keypoint_{i}_y'])\n    writer.writerow(header)\n\n            # Iterate over the results and extract keypoints\n    for result in results:\n        image_name = os.path.basename(result.path)  # Get the image filename\n    \n        if hasattr(result, 'keypoints') and result.keypoints is not None and len(result.keypoints) > 0:\n            # Access the first detected pose (unwrap the first dimension)\n            keypoints = result.keypoints[0].cpu().numpy()  # Get raw keypoint data\n            \n            # Convert to numpy array with only (x, y) coordinates\n            keypoints_xy = result.keypoints.xy[0].cpu().numpy()  # (17, 2)\n    \n            # Verify the keypoint shape\n            if keypoints_xy.shape == (17, 2):\n                # Prepare keypoint data for CSV\n                keypoint_data = [image_name]  # Start with the image name\n                \n                # Extract x, y coordinates for each keypoint\n                for kp in keypoints_xy:\n                    keypoint_data.extend([kp[0], kp[1]])  # Only x, y (ignore confidence)\n    \n                # Write keypoint data to the CSV file\n                writer.writerow(keypoint_data)\n            else:\n                print(f\"Unexpected keypoint shape for image {image_name}: {keypoints_xy.shape}\")\n        else:\n            # Log the issue if no keypoints are detected\n            print(f\"No keypoints detected for image: {image_name}\")\n    print(f\"Keypoint data saved to: {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:40:49.879716Z","iopub.execute_input":"2024-12-16T13:40:49.880041Z","iopub.status.idle":"2024-12-16T13:40:50.635003Z","shell.execute_reply.started":"2024-12-16T13:40:49.880012Z","shell.execute_reply":"2024-12-16T13:40:50.634062Z"}},"outputs":[{"name":"stdout","text":"Unexpected keypoint shape for image fall_2_forward_falls_frame018.jpg: (0, 2)\nUnexpected keypoint shape for image fall_2_right_falls_frame021.jpg: (0, 2)\nUnexpected keypoint shape for image fall_2_right_falls_frame022.jpg: (0, 2)\nUnexpected keypoint shape for image fall_3_standing_falls_frame012.jpg: (0, 2)\nUnexpected keypoint shape for image fall_4_left_falls_frame042.jpg: (0, 2)\nUnexpected keypoint shape for image fall_4_left_falls_frame043.jpg: (0, 2)\nUnexpected keypoint shape for image fall_4_left_falls_frame045.jpg: (0, 2)\nKeypoint data saved to: /kaggle/working/yolo_keypoints.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ndata = pd.read_csv(\"/kaggle/input/keypoints/yolo_keypoints (1).csv\")\n\n# Automatically label the data based on the image_name\ndef label_image(image_name):\n    image_name = image_name.lower()  # Convert to lowercase for case-insensitive comparison\n    if \"non_fall\" in image_name:  # Check \"non_fall\" first to avoid it being overridden by \"fall\"\n        return 0  # Label as non-fall\n    elif \"fall\" in image_name:  # Check \"fall\" afterward\n        return 1  # Label as fall\n    else:\n        return None \n\n# Apply the function to create a 'label' column\ndata['label'] = data['image_name'].apply(label_image)\n\n# Drop rows with missing labels (if any image_name doesn't contain 'fall' or 'non_fall')\ndata = data.dropna(subset=['label'])\n\n# Save the updated CSV (optional)\noutput_csv = \"/kaggle/working/yolo_keypoints_labeled.csv\"\ndata.to_csv(output_csv, index=False)\n\nprint(f\"Labeled data saved to: {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:40:50.636038Z","iopub.execute_input":"2024-12-16T13:40:50.636312Z","iopub.status.idle":"2024-12-16T13:40:50.845608Z","shell.execute_reply.started":"2024-12-16T13:40:50.636286Z","shell.execute_reply":"2024-12-16T13:40:50.844783Z"}},"outputs":[{"name":"stdout","text":"Labeled data saved to: /kaggle/working/yolo_keypoints_labeled.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport xgboost as xgb\nimport joblib\n\n# Step 1: Load the labeled data\ndata = pd.read_csv(\"/kaggle/working/yolo_keypoints_labeled.csv\")\n\n# Step 2: Split into features (X) and labels (y)\n# Drop 'image_name' since it's not a feature for training\nX = data.drop(columns=['image_name', 'label'])\ny = data['label']\n\n# Step 3: Train-test split (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Step 4: Train the XGBoost Classifier\nmodel = xgb.XGBClassifier(\n    n_estimators=300,   # Number of trees\n    learning_rate=0.1,  # Step size shrinkage\n    max_depth=5,        # Maximum depth of trees\n    random_state=42,    # Seed for reproducibility\n    use_label_encoder=False\n)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Step 5: Evaluate the Model\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Print a classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Step 6: Save the Model\noutput_model = \"/kaggle/working/xgboost_fall_detection_model.pkl\"\njoblib.dump(model, output_model)\nprint(f\"Model saved to: {output_model}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:40:50.846539Z","iopub.execute_input":"2024-12-16T13:40:50.846805Z","iopub.status.idle":"2024-12-16T13:40:52.424563Z","shell.execute_reply.started":"2024-12-16T13:40:50.846780Z","shell.execute_reply":"2024-12-16T13:40:52.423691Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [13:40:52] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"use_label_encoder\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.99\nClassification Report:\n              precision    recall  f1-score   support\n\n         0.0       0.99      1.00      0.99       550\n         1.0       1.00      0.98      0.99       308\n\n    accuracy                           0.99       858\n   macro avg       0.99      0.99      0.99       858\nweighted avg       0.99      0.99      0.99       858\n\nModel saved to: /kaggle/working/xgboost_fall_detection_model.pkl\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport shutil\nfrom ultralytics import YOLO\n\ndef load_test_images_in_batches(test_dir, target_size=(640, 640), batch_size=32):\n    \"\"\"\n    Loads and preprocesses images from the test folder in batches.\n    \"\"\"\n    image_files = [f for f in os.listdir(test_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n\n    for i in range(0, len(image_files), batch_size):\n        batch_files = image_files[i:i + batch_size]\n        batch_images = []\n        batch_ids = []\n\n        for file in batch_files:\n            img_path = os.path.join(test_dir, file)\n            try:\n                # Load and preprocess the image\n                img = load_img(img_path, target_size=target_size)\n                img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n                batch_images.append(img_array)\n                batch_ids.append(file)\n            except Exception as e:\n                print(f\"Error processing {file}: {e}\")\n\n        yield np.array(batch_images), batch_ids\n\n# Step 1: Test Directory\ntest_dir = '/kaggle/input/dataslayerdatasets/test'\n\n# Step 2: Validate File Paths\nif not os.path.exists(test_dir) or len(os.listdir(test_dir)) == 0:\n    raise FileNotFoundError(f\"No images found in directory: {test_dir}\")\n\n# Step 3: Create YOLO Input Directory\nyolo_input_dir = \"/kaggle/working/test\"\nos.makedirs(yolo_input_dir, exist_ok=True)\n\n# Copy images into YOLO input directory with unique filenames and validation\nimage_files = [f for f in os.listdir(test_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\nfor img_file in image_files:\n    img_path = os.path.join(test_dir, img_file)\n    if os.path.exists(img_path):\n        unique_filepath = os.path.join(yolo_input_dir, img_file)  # Avoid modifying filenames\n        shutil.copy(img_path, unique_filepath)\n    else:\n        print(f\"File not found or inaccessible: {img_path}\")\n\n# Verify the total number of files copied\ncopied_files = os.listdir(yolo_input_dir)\nprint(f\"Total files copied to YOLO input directory: {len(copied_files)}\")\n\n# Step 4: Initialize YOLOv8 Pose Model\nmodel = YOLO('yolov8n-pose.pt')\n\n# Step 5: Run YOLO Predictions\nresults = model.predict(\n    source=yolo_input_dir,  # Directory containing images\n    task=\"pose\",\n    imgsz=640,\n    verbose=False,\n    save=True  # Save predictions\n)\n\n# Output the saved results directory\nprint(f\"Predictions saved in: {results[0].save_dir}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:40:52.426909Z","iopub.execute_input":"2024-12-16T13:40:52.427175Z","iopub.status.idle":"2024-12-16T13:43:12.717499Z","shell.execute_reply.started":"2024-12-16T13:40:52.427150Z","shell.execute_reply":"2024-12-16T13:43:12.716289Z"}},"outputs":[{"name":"stdout","text":"Total files copied to YOLO input directory: 2152\n\nWARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\nerrors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n\nExample:\n    results = model(source=..., stream=True)  # generator of Results objects\n    for r in results:\n        boxes = r.boxes  # Boxes object for bbox outputs\n        masks = r.masks  # Masks object for segment masks outputs\n        probs = r.probs  # Class probabilities for classification outputs\n\nResults saved to \u001b[1mruns/pose/predict2\u001b[0m\nPredictions saved in: runs/pose/predict2\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import csv\nimport os\n\n# Save keypoints to CSV\noutput_csv = \"/kaggle/working/yolo_predictions.csv\"\nwith open(output_csv, mode='w', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    \n    # Write header: image_name + flattened keypoints (x, y for 17 keypoints)\n    header = ['image_name'] + [f'keypoint_{i}_x' for i in range(1, 18)] + [f'keypoint_{i}_y' for i in range(1, 18)]\n    writer.writerow(header)\n\n    # Iterate through results\n    for result in results:\n        if hasattr(result, 'keypoints') and result.keypoints is not None:\n            keypoints_tensor = result.keypoints.xy.cpu().numpy()  # Extract keypoints (x, y)\n            image_name = os.path.basename(result.path)  # Get the image filename\n\n            for detection_keypoints in keypoints_tensor:  # Iterate over detections\n                flattened_keypoints = detection_keypoints.flatten()  # Flatten (x, y) coordinates for 17 keypoints\n                writer.writerow([image_name] + list(flattened_keypoints))  # Write to CSV\n\nprint(f\"Keypoints saved to: {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:43:12.718835Z","iopub.execute_input":"2024-12-16T13:43:12.719113Z","iopub.status.idle":"2024-12-16T13:43:12.805035Z","shell.execute_reply.started":"2024-12-16T13:43:12.719086Z","shell.execute_reply":"2024-12-16T13:43:12.804133Z"}},"outputs":[{"name":"stdout","text":"Keypoints saved to: /kaggle/working/yolo_predictions.csv\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the test set keypoints CSV\ntest_csv = \"/kaggle/working/yolo_predictions.csv\"\ntest_keypoints = pd.read_csv(test_csv)\n\n# Extract image names and keypoints\nimage_names = test_keypoints['image_name']\nkeypoints = test_keypoints.drop('image_name', axis=1).values\n\n# Preprocess keypoints (skip scaling if scaler is unavailable)\n# Replace this with the appropriate saved scaler loading code if available\ntry:\n    from joblib import load\n    scaler = load(\"/kaggle/working/scaler.pkl\")\n    keypoints_scaled = scaler.transform(keypoints)\nexcept FileNotFoundError:\n    print(\"Scaler not found. Proceeding without scaling.\")\n    keypoints_scaled = keypoints\n\n# Load the pre-trained XGBoost model (saved using joblib)\nfrom joblib import load\nxgb_model = load(\"/kaggle/working/xgboost_fall_detection_model.pkl\")\n\n# Make predictions\npredictions = xgb_model.predict(keypoints_scaled)\n\n# Convert probabilities to binary labels (assuming binary classification)\nlabels = (predictions > 0.5).astype(int)\n\n# Save predictions with image names to a new CSV\noutput_csv = \"/kaggle/working/test_predictions.csv\"\noutput_df = pd.DataFrame({'id': image_names, 'label': labels})\noutput_df.to_csv(output_csv, index=False)\n\nprint(f\"Predictions saved to: {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:43:12.806137Z","iopub.execute_input":"2024-12-16T13:43:12.806384Z","iopub.status.idle":"2024-12-16T13:43:12.844902Z","shell.execute_reply.started":"2024-12-16T13:43:12.806361Z","shell.execute_reply":"2024-12-16T13:43:12.843908Z"}},"outputs":[{"name":"stdout","text":"Scaler not found. Proceeding without scaling.\nPredictions saved to: /kaggle/working/test_predictions.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\ndef load_test_images_in_batches(test_dir, target_size=(640, 640), batch_size=32):\n    \"\"\"\n    Loads and preprocesses images from the test folder in batches.\n\n    Args:\n        test_dir (str): Directory containing test images.\n        target_size (tuple): Desired image size (width, height).\n        batch_size (int): Number of images to process per batch.\n\n    Yields:\n        tuple: Batch of images as a NumPy array and corresponding image IDs.\n    \"\"\"\n    image_files = [f for f in os.listdir(test_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n\n    for i in range(0, len(image_files), batch_size):\n        batch_files = image_files[i:i + batch_size]\n        batch_images = []\n        batch_ids = []\n\n        for file in batch_files:\n            img_path = os.path.join(test_dir, file)\n            try:\n                # Load and preprocess the image\n                img = load_img(img_path, target_size=target_size)\n                img_array = img_to_array(img) / 255.0  # Novrmalize to [0, 1]\n                batch_images.append(img_array)\n                batch_ids.append(file)\n            except Exception as e:\n                print(f\"Error processing {file}: {e}\")\n\n        yield np.array(batch_images), batch_ids\n\n# Example usage\ntest_dir = '/kaggle/input/dataslayerdatasets/test'\nfor batch_images, batch_ids in load_test_images_in_batches(test_dir):\n    print(f\"Processed batch of {len(batch_images)} images.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:43:12.846009Z","iopub.execute_input":"2024-12-16T13:43:12.846254Z","iopub.status.idle":"2024-12-16T13:43:30.408635Z","shell.execute_reply.started":"2024-12-16T13:43:12.846231Z","shell.execute_reply":"2024-12-16T13:43:30.407549Z"}},"outputs":[{"name":"stdout","text":"Processed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 32 images.\nProcessed batch of 8 images.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Function to load CSV data\ndef load_csv(file_path):\n    \"\"\"Loads a CSV file and returns a dictionary with photo ID as key and label as value.\"\"\"\n    data_dict = {}\n    with open(file_path, mode='r') as csvfile:\n        csv_reader = csv.reader(csvfile, delimiter=',')\n        next(csv_reader)  # Skip the header\n        \n        for row in csv_reader:\n            # Check if the row contains a valid format\n            if len(row) != 2:\n                print(f\"Skipping invalid row: {row}\")\n                continue\n            \n            full_path_or_id, label = row\n            # Extract photo ID from the full path if necessary\n            photo_id = Path(full_path_or_id).name  # This ensures we only get the filename\n            data_dict[photo_id] = int(label)  # Convert label to integer\n    \n    return data_dict\n\n# Function to calculate accuracy and log incorrect predictions\ndef calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv):\n    \"\"\"\n    Compares the predicted labels to the ground truth labels using the photo IDs as keys.\n    Logs incorrect predictions for visualization.\n    \"\"\"\n    # Load both CSVs into dictionaries\n    predicted = load_csv(predicted_csv)\n    ground_truth = load_csv(ground_truth_csv)\n    \n    # Initialize counters\n    correct = 0\n    total = 0\n    incorrect_predictions = []  # Store tuples of (photo_id, predicted_label, true_label)\n    \n    for photo_id, true_label in ground_truth.items():\n        # Check if the photo ID exists in the predicted data\n        if photo_id in predicted:\n            total += 1  # Increment total for every matched ID\n            if predicted[photo_id] == true_label:\n                correct += 1  # Increment correct if labels match\n            else:\n                incorrect_predictions.append((photo_id, predicted[photo_id], true_label))\n        else:\n            print(f\"Warning: Photo ID {photo_id} not found in predictions.\")\n    \n    # Calculate accuracy\n    accuracy = correct / total if total > 0 else 0\n    return accuracy, correct, total, incorrect_predictions\n\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom PIL import Image\nimport math\n\ndef visualize_incorrect_predictions(incorrect_predictions, image_dir, grid_size=5, resize_to=(100, 100)):\n    \"\"\"\n    Displays the images for the incorrect predictions in a compact grid layout with resized images.\n    \"\"\"\n    num_images = min(len(incorrect_predictions), grid_size * (grid_size *4))  # Max images to show\n    rows = math.ceil(num_images / grid_size)\n    cols = grid_size\n\n    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))  # Smaller figure size\n    axes = axes.flatten()  # Flatten for easy iteration\n\n    for idx, (photo_id, predicted_label, true_label) in enumerate(incorrect_predictions[:num_images]):\n        image_path = Path(image_dir) / photo_id  # Construct the full image path\n        \n        # Check if the image exists\n        if not image_path.exists():\n            print(f\"Image not found: {image_path}\")\n            axes[idx].axis(\"off\")\n            continue\n        \n        try:\n            # Load and resize the image\n            img = Image.open(image_path)\n            img = img.resize(resize_to, Image.Resampling.LANCZOS)  # Resize to reduce load time\n            \n            # Display the image\n            axes[idx].imshow(img)\n            axes[idx].axis(\"off\")\n            axes[idx].set_title(f\"Pred: {predicted_label}\\nTrue: {true_label}\", fontsize=8)\n        except Exception as e:\n            print(f\"Error loading image {photo_id}: {e}\")\n            axes[idx].axis(\"off\")\n    \n    # Hide any unused axes\n    for idx in range(num_images, len(axes)):\n        axes[idx].axis(\"off\")\n    \n    plt.tight_layout(pad=1.0)\n    plt.show()\n# File paths for comparison\npredicted_csv = '/kaggle/working/predictions_threshold_0.25.csv'  # Replace with your predicted CSV path\nground_truth_csv = '/kaggle/input/label-diri/file_labels (3).csv'  # Replace with your ground truth CSV path\nimage_directory = '/kaggle/input/dataslayerdatasets/test'  # Replace with the directory containing the images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:43:30.409986Z","iopub.execute_input":"2024-12-16T13:43:30.410266Z","iopub.status.idle":"2024-12-16T13:43:30.425129Z","shell.execute_reply.started":"2024-12-16T13:43:30.410238Z","shell.execute_reply":"2024-12-16T13:43:30.424192Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\ndef plot_confusion_matrix(y_true, y_pred, labels, title=\"Confusion Matrix\"):\n    \"\"\"\n    Generate and plot a confusion matrix with a heatmap.\n    \"\"\"\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    \n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False)\n    plt.title(title)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:43:30.426237Z","iopub.execute_input":"2024-12-16T13:43:30.426608Z","iopub.status.idle":"2024-12-16T13:43:30.524050Z","shell.execute_reply.started":"2024-12-16T13:43:30.426581Z","shell.execute_reply":"2024-12-16T13:43:30.523025Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\npredicted_csv = output_csv  # Replace with your predicted CSV path\nground_truth_csv = '/kaggle/input/label-diri/file_labels (3).csv'  # Replace with your ground truth CSV path\n\n# Get accuracy and incorrect predictions\naccuracy, correct, total, incorrect_predictions, y_true, y_pred = calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv)\n\n# Print accuracy\nprint(f\"Accuracy: {accuracy * 100:.2f}% ({correct}/{total} correct predictions)\")\n\n# Plot the confusion matrix\nlabels = [0, 1]  # Change if you have more classes\nplot_confusion_matrix(y_true, y_pred, labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:43:30.525229Z","iopub.execute_input":"2024-12-16T13:43:30.525716Z","iopub.status.idle":"2024-12-16T13:43:30.774268Z","shell.execute_reply.started":"2024-12-16T13:43:30.525685Z","shell.execute_reply":"2024-12-16T13:43:30.772950Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m ground_truth_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/label-diri/file_labels (3).csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your ground truth CSV path\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get accuracy and incorrect predictions\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m accuracy, correct, total, incorrect_predictions, y_true, y_pred \u001b[38;5;241m=\u001b[39m calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print accuracy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m correct predictions)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"],"ename":"ValueError","evalue":"not enough values to unpack (expected 6, got 4)","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"# Example usage\npredicted_csv = '/kaggle/working/test_predictions.csv'  # Replace with your predicted CSV path\nground_truth_csv = '/kaggle/input/label-diri/file_labels (3).csv'  # Replace with your ground truth CSV path\n\n# Get accuracy and incorrect predictions\naccuracy, correct, total, incorrect_predictions, y_true, y_pred = calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv)\n\n# Print accuracy\nprint(f\"Accuracy: {accuracy * 100:.2f}% ({correct}/{total} correct predictions)\")\n\n# Plot the confusion matrix\nlabels = [0, 1]  # Change if you have more classes\nplot_confusion_matrix(y_true, y_pred, labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:43:30.775227Z","iopub.status.idle":"2024-12-16T13:43:30.775586Z","shell.execute_reply.started":"2024-12-16T13:43:30.775405Z","shell.execute_reply":"2024-12-16T13:43:30.775422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}