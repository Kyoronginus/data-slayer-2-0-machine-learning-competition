{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:33:47.763976Z",
     "iopub.status.busy": "2024-12-18T11:33:47.763108Z",
     "iopub.status.idle": "2024-12-18T11:33:57.741690Z",
     "shell.execute_reply": "2024-12-18T11:33:57.740513Z",
     "shell.execute_reply.started": "2024-12-18T11:33:47.763923Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\tohru\\anaconda3\\lib\\site-packages (8.3.50)\n",
      "Requirement already satisfied: torch in c:\\users\\tohru\\anaconda3\\lib\\site-packages (2.4.1+cu121)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\tohru\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tohru\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\tohru\\anaconda3\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (0.19.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\tohru\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tohru\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics torch opencv-python scikit-learn pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:34:54.629354Z",
     "iopub.status.busy": "2024-12-18T11:34:54.628957Z",
     "iopub.status.idle": "2024-12-18T11:34:54.635749Z",
     "shell.execute_reply": "2024-12-18T11:34:54.634712Z",
     "shell.execute_reply.started": "2024-12-18T11:34:54.629320Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-18T11:34:59.012112Z",
     "iopub.status.busy": "2024-12-18T11:34:59.011731Z",
     "iopub.status.idle": "2024-12-18T11:34:59.017318Z",
     "shell.execute_reply": "2024-12-18T11:34:59.016219Z",
     "shell.execute_reply.started": "2024-12-18T11:34:59.012081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:35:01.489499Z",
     "iopub.status.busy": "2024-12-18T11:35:01.488495Z",
     "iopub.status.idle": "2024-12-18T11:35:01.496886Z",
     "shell.execute_reply": "2024-12-18T11:35:01.495881Z",
     "shell.execute_reply.started": "2024-12-18T11:35:01.489444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(root_dir):\n",
    "    \"\"\"\n",
    "    Load data from the specified root directory\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): Root directory containing subject folders\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Lists of image paths and corresponding labels\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for subject in os.listdir(root_dir):\n",
    "        subject_path = os.path.join(root_dir, subject)\n",
    "        if os.path.isdir(subject_path):\n",
    "            for activity_type in os.listdir(subject_path):\n",
    "                label = 1 if activity_type == 'fall' else 0\n",
    "                activity_path = os.path.join(subject_path, activity_type)\n",
    "                for activity_class in os.listdir(activity_path):\n",
    "                    class_path = os.path.join(activity_path, activity_class)\n",
    "                    for file in os.listdir(class_path):\n",
    "                        data.append(os.path.join(class_path, file))\n",
    "                        labels.append(label)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:35:04.464238Z",
     "iopub.status.busy": "2024-12-18T11:35:04.463864Z",
     "iopub.status.idle": "2024-12-18T11:35:04.474143Z",
     "shell.execute_reply": "2024-12-18T11:35:04.473067Z",
     "shell.execute_reply.started": "2024-12-18T11:35:04.464206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_yolo_dataset(data_paths, labels, output_dir):\n",
    "    \"\"\"\n",
    "    Prepare dataset structure for YOLO training\n",
    "    \n",
    "    Args:\n",
    "        data_paths (list): List of image file paths\n",
    "        labels (list): Corresponding labels\n",
    "        output_dir (str): Directory to save prepared dataset\n",
    "    \n",
    "    Returns:\n",
    "        dict: Paths to train and validation directories\n",
    "    \"\"\"\n",
    "    # Create absolute paths\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "    \n",
    "    # Ensure all necessary directories exist\n",
    "    os.makedirs(os.path.join(output_dir, 'images', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images', 'val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels', 'val'), exist_ok=True)\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        data_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    def copy_and_create_labels(image_paths, labels, split):\n",
    "        \"\"\"\n",
    "        Copy images and create YOLO-format label files\n",
    "        \n",
    "        Args:\n",
    "            image_paths (list): Paths to image files\n",
    "            labels (list): Corresponding labels\n",
    "            split (str): 'train' or 'val'\n",
    "        \"\"\"\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            # Copy image\n",
    "            img_filename = os.path.basename(img_path)\n",
    "            dest_img_path = os.path.join(output_dir, 'images', split, img_filename)\n",
    "            shutil.copy(img_path, dest_img_path)\n",
    "            \n",
    "            # Create label file\n",
    "            label_filename = os.path.splitext(img_filename)[0] + '.txt'\n",
    "            label_path = os.path.join(output_dir, 'labels', split, label_filename)\n",
    "            \n",
    "            # For fall detection, we'll create a full-image label\n",
    "            # YOLO format: <class> <x_center> <y_center> <width> <height>\n",
    "            with open(label_path, 'w') as f:\n",
    "                # Assuming label 0 is no fall, 1 is fall\n",
    "                f.write(f\"{label} 0.5 0.5 1.0 1.0\")\n",
    "    \n",
    "    # Prepare train and validation sets\n",
    "    copy_and_create_labels(train_paths, train_labels, 'train')\n",
    "    copy_and_create_labels(val_paths, val_labels, 'val')\n",
    "    \n",
    "    return {\n",
    "        'train': os.path.join(output_dir, 'images', 'train'),\n",
    "        'val': os.path.join(output_dir, 'images', 'val')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:35:12.772020Z",
     "iopub.status.busy": "2024-12-18T11:35:12.771358Z",
     "iopub.status.idle": "2024-12-18T11:35:12.780675Z",
     "shell.execute_reply": "2024-12-18T11:35:12.779391Z",
     "shell.execute_reply.started": "2024-12-18T11:35:12.771957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_yolo_config(dataset_paths, config_path='fall_detection.yaml'):\n",
    "    \"\"\"\n",
    "    Create YOLO configuration YAML file\n",
    "    \n",
    "    Args:\n",
    "        dataset_paths (dict): Paths to train and validation datasets\n",
    "        config_path (str): Path to save the configuration file\n",
    "    \"\"\"\n",
    "    # Ensure absolute paths\n",
    "    train_path = os.path.abspath(dataset_paths['train'])\n",
    "    val_path = os.path.abspath(dataset_paths['val'])\n",
    "    \n",
    "    yolo_config = {\n",
    "        'train': train_path,\n",
    "        'val': val_path,\n",
    "        'nc': 2,  # Number of classes (fall and no fall)\n",
    "        'names': ['no_fall', 'fall']\n",
    "    }\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(os.path.abspath(config_path)), exist_ok=True)\n",
    "    \n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.dump(yolo_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:35:13.331044Z",
     "iopub.status.busy": "2024-12-18T11:35:13.330616Z",
     "iopub.status.idle": "2024-12-18T11:35:13.341833Z",
     "shell.execute_reply": "2024-12-18T11:35:13.340662Z",
     "shell.execute_reply.started": "2024-12-18T11:35:13.331009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_yolo_model(root_dir, output_dir='yolov8n/train', epochs=50):\n",
    "    \"\"\"\n",
    "    Comprehensive debugging for YOLO model training\n",
    "    \"\"\"\n",
    "    # Print current working directory and relevant paths\n",
    "    print(\"Current Working Directory:\", os.getcwd())\n",
    "    print(\"Root Directory:\", root_dir)\n",
    "    print(\"Output Directory:\", output_dir)\n",
    "\n",
    "    # Check input directory contents\n",
    "    print(\"\\n--- Input Directory Contents ---\")\n",
    "    try:\n",
    "        print(os.listdir(root_dir))\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing root directory: {e}\")\n",
    "\n",
    "    # Load data\n",
    "    data_paths, labels = load_data(root_dir)\n",
    "    print(f\"\\nLoaded {len(data_paths)} samples.\")\n",
    "    \n",
    "    # Prepare dataset for YOLO\n",
    "    dataset_paths = prepare_yolo_dataset(data_paths, labels, output_dir)\n",
    "    \n",
    "    # Create YOLO configuration\n",
    "    config_path = 'yolov8n/fall_detection.yaml'\n",
    "    create_yolo_config(dataset_paths, config_path)\n",
    "\n",
    "    # Initialize model\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # Attempt training\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=config_path,\n",
    "            epochs=epochs,\n",
    "            imgsz=640,\n",
    "            batch=16,\n",
    "            device=0,  # Use GPU if available\n",
    "            project='yolov8n',  # Explicitly set project directory\n",
    "            name='fall_detection',  # Set a specific name for the run\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Search for model files\n",
    "        print(\"\\n--- Searching for model files ---\")\n",
    "        for root, dirs, files in os.walk('yolov8n'):\n",
    "            for file in files:\n",
    "                if file == 'best.pt':\n",
    "                    model_path = os.path.join(root, file)\n",
    "                    print(f\"Found model at: {model_path}\")\n",
    "                    \n",
    "                    # Attempt to load the model\n",
    "                    try:\n",
    "                        loaded_model = YOLO(model_path)\n",
    "                        print(\"Model successfully loaded!\")\n",
    "                        return model_path\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading model: {e}\")\n",
    "        \n",
    "        print(\"No 'best.pt' model found in yolov8n directory\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed with error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:35:14.274912Z",
     "iopub.status.busy": "2024-12-18T11:35:14.274144Z",
     "iopub.status.idle": "2024-12-18T11:35:14.287867Z",
     "shell.execute_reply": "2024-12-18T11:35:14.286546Z",
     "shell.execute_reply.started": "2024-12-18T11:35:14.274866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2  # OpenCV is needed for image reading/writing\n",
    "\n",
    "def augment_and_save_from_root(root_dir, output_dir, augment_ratio=2, save_original=True):\n",
    "    \"\"\"\n",
    "    Perform data augmentation on a dataset organized by subject/activity type.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root directory containing subject/activity folders.\n",
    "        output_dir (str): Directory to save augmented images.\n",
    "        augment_ratio (int): Number of augmented images to generate per input image.\n",
    "        save_original (bool): Whether to save the original image alongside augmented ones.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Define augmentation pipeline\n",
    "    augmentation = A.Compose([\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        # A.RandomBrightnessContrast(p=0.3),\n",
    "        # A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.7),\n",
    "        # A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=0.3),\n",
    "        # A.RandomResizedCrop(height=640, width=640, scale=(0.8, 1.0), p=0.5),\n",
    "        # A.GaussianBlur(blur_limit=3, p=0.2),\n",
    "        # A.CLAHE(p=0.2),\n",
    "        # A.ToGray(p=0.1),  # Convert some images to grayscale for variety\n",
    "    ])\n",
    "\n",
    "    augmented_data = []\n",
    "    augmented_labels = []\n",
    "    errors = []\n",
    "\n",
    "    for subject in os.listdir(root_dir):\n",
    "        subject_path = os.path.join(root_dir, subject)\n",
    "        if os.path.isdir(subject_path):\n",
    "            for activity_type in os.listdir(subject_path):\n",
    "                label = 1 if activity_type == 'fall' else 0\n",
    "                activity_path = os.path.join(subject_path, activity_type)\n",
    "                for activity_class in os.listdir(activity_path):\n",
    "                    class_path = os.path.join(activity_path, activity_class)\n",
    "                    for file in os.listdir(class_path):\n",
    "                        img_path = os.path.join(class_path, file)\n",
    "                        image = cv2.imread(img_path)\n",
    "                        if image is None:\n",
    "                            errors.append(img_path)\n",
    "                            continue\n",
    "\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                        # Create output directory structure\n",
    "                        output_class_dir = os.path.join(output_dir, subject, activity_type, activity_class)\n",
    "                        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "                        # Save original image if required\n",
    "                        if save_original:\n",
    "                            save_path = os.path.join(output_class_dir, f\"{file.split('.')[0]}_original.jpg\")\n",
    "                            cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "                            augmented_data.append(save_path)\n",
    "                            augmented_labels.append(label)\n",
    "\n",
    "                        # Generate augmented images\n",
    "                        for i in range(augment_ratio):\n",
    "                            augmented = augmentation(image=image)\n",
    "                            augmented_image = augmented[\"image\"]\n",
    "\n",
    "                            # Save augmented image\n",
    "                            aug_save_path = os.path.join(output_class_dir, f\"{file.split('.')[0]}_aug{i}.jpg\")\n",
    "                            cv2.imwrite(aug_save_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "                            augmented_data.append(aug_save_path)\n",
    "                            augmented_labels.append(label)\n",
    "\n",
    "    # Log errors if any\n",
    "    if errors:\n",
    "        print(\"\\n--- Errors During Augmentation ---\")\n",
    "        for err in errors:\n",
    "            print(f\"Could not process image: {err}\")\n",
    "\n",
    "    print(f\"\\nSaved {len(augmented_data)} images to {output_dir}\")\n",
    "    return augmented_data, augmented_labels\n",
    "import albumentations as A\n",
    "import cv2  # OpenCV is needed for image reading/writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:38:28.623109Z",
     "iopub.status.busy": "2024-12-18T11:38:28.622681Z",
     "iopub.status.idle": "2024-12-18T11:38:36.463379Z",
     "shell.execute_reply": "2024-12-18T11:38:36.462230Z",
     "shell.execute_reply.started": "2024-12-18T11:38:28.623076Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\tohru\\data-slayer-2-0-machine-learning-competition\\Prediction_program\n",
      "Root Directory: train\n",
      "Output Directory: yolov8n/train\n",
      "\n",
      "--- Input Directory Contents ---\n",
      "['subject-1', 'subject-2', 'subject-3', 'subject-4']\n",
      "\n",
      "Loaded 4294 samples.\n",
      "New https://pypi.org/project/ultralytics/8.3.51 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.50  Python-3.12.4 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=yolov8n/fall_detection.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=yolov8n, name=fall_detection3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolov8n\\fall_detection3\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov8n\\fall_detection3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\tohru\\data-slayer-2-0-machine-learning-competition\\Prediction_program\\yolov8n\\train\\labels\\train.cache... 249 images, 0 backgrounds, 0 corrupt: 100%|██████████| 249/249 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root_dir = 'train'  # Replace with the path to your root directory\n",
    "    # augmented_dir = 'augmentedtrain'  # Replace with the output directory path\n",
    "\n",
    "    # # Apply data augmentation\n",
    "    # print(\"Applying data augmentation...\")\n",
    "    # augmented_data, augmented_labels = augment_and_save_from_root(root_dir, augmented_dir, augment_ratio=1)\n",
    "    # print(f\"Augmented data saved to: {augmented_dir}\")\n",
    "\n",
    "    # # Step 2: Train YOLO model on augmented data\n",
    "    # print(\"Training YOLO model on augmented data...\")\n",
    "    # best_model_path = train_yolo_model(augmented_dir)\n",
    "    # print(f\"Best model saved at: {best_model_path}\")\n",
    "\n",
    "    best_model_path = train_yolo_model(root_dir)\n",
    "    print(f\"Best model saved at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:35:46.984412Z",
     "iopub.status.busy": "2024-12-18T11:35:46.984000Z",
     "iopub.status.idle": "2024-12-18T11:35:47.082259Z",
     "shell.execute_reply": "2024-12-18T11:35:47.080892Z",
     "shell.execute_reply.started": "2024-12-18T11:35:46.984377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 99\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlots successfully generated from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_csv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Replace `your_model_path` with the actual path to `best.pt`\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[43mplot_training_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 16\u001b[0m, in \u001b[0;36mplot_training_metrics\u001b[1;34m(best_model_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mAutomatically locate the `results.csv` file and plot YOLO training metrics.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Derive the path to `results.csv`\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get the directory of best.pt\u001b[39;00m\n\u001b[0;32m     17\u001b[0m results_csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(base_dir), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Check if results.csv exists\u001b[39;00m\n",
      "File \u001b[1;32m<frozen ntpath>:277\u001b[0m, in \u001b[0;36mdirname\u001b[1;34m(p)\u001b[0m\n",
      "File \u001b[1;32m<frozen ntpath>:241\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(p)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_training_metrics(best_model_path):\n",
    "#     \"\"\"\n",
    "#     Automatically locate the `results.csv` file and plot YOLO training metrics.\n",
    "    \n",
    "#     Args:\n",
    "#         best_model_path (str): Path to the best YOLO model (e.g., best.pt).\n",
    "    \n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     # Derive the path to `results.csv`\n",
    "#     base_dir = os.path.dirname(best_model_path)  # Get the directory of best.pt\n",
    "#     results_csv_path = os.path.join(os.path.dirname(base_dir), 'results.csv')\n",
    "    \n",
    "#     # Check if results.csv exists\n",
    "#     if not os.path.exists(results_csv_path):\n",
    "#         raise FileNotFoundError(f\"Results CSV not found at {results_csv_path}\")\n",
    "\n",
    "#     # Load training results\n",
    "#     try:\n",
    "#         results = pd.read_csv(results_csv_path)\n",
    "#     except Exception as e:\n",
    "#         raise ValueError(f\"Failed to read {results_csv_path}: {e}\")\n",
    "    \n",
    "#     # Validate required columns\n",
    "#     required_columns = [\n",
    "#         'epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n",
    "#         'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\n",
    "#         'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)',\n",
    "#         'lr/pg0', 'lr/pg1', 'lr/pg2'\n",
    "#     ]\n",
    "#     for col in required_columns:\n",
    "#         if col not in results.columns:\n",
    "#             raise ValueError(f\"Missing required column '{col}' in results.csv\")\n",
    "    \n",
    "#     # Plot training metrics\n",
    "#     plt.figure(figsize=(18, 10))\n",
    "\n",
    "#     # Training Losses\n",
    "#     plt.subplot(2, 3, 1)\n",
    "#     plt.plot(results['epoch'], results['train/box_loss'], label='Box Loss', color='blue')\n",
    "#     plt.plot(results['epoch'], results['train/cls_loss'], label='Class Loss', color='orange')\n",
    "#     plt.plot(results['epoch'], results['train/dfl_loss'], label='DFL Loss', color='green')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.title('Training Loss')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Validation Losses\n",
    "#     plt.subplot(2, 3, 2)\n",
    "#     plt.plot(results['epoch'], results['val/box_loss'], label='Val Box Loss', color='blue')\n",
    "#     plt.plot(results['epoch'], results['val/cls_loss'], label='Val Class Loss', color='orange')\n",
    "#     plt.plot(results['epoch'], results['val/dfl_loss'], label='Val DFL Loss', color='green')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.title('Validation Loss')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Metrics: Precision, Recall, mAP50, mAP50-95\n",
    "#     plt.subplot(2, 3, 3)\n",
    "#     plt.plot(results['epoch'], results['metrics/precision(B)'], label='Precision', color='blue')\n",
    "#     plt.plot(results['epoch'], results['metrics/recall(B)'], label='Recall', color='orange')\n",
    "#     plt.plot(results['epoch'], results['metrics/mAP50(B)'], label='mAP50', color='green')\n",
    "#     plt.plot(results['epoch'], results['metrics/mAP50-95(B)'], label='mAP50-95', color='red')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Metrics')\n",
    "#     plt.title('Validation Metrics')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Learning Rates\n",
    "#     plt.subplot(2, 3, 4)\n",
    "#     plt.plot(results['epoch'], results['lr/pg0'], label='LR pg0', color='purple')\n",
    "#     plt.plot(results['epoch'], results['lr/pg1'], label='LR pg1', color='blue')\n",
    "#     plt.plot(results['epoch'], results['lr/pg2'], label='LR pg2', color='green')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Learning Rate')\n",
    "#     plt.title('Learning Rate Schedule')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Epoch vs Time\n",
    "#     plt.subplot(2, 3, 5)\n",
    "#     plt.plot(results['epoch'], results['time'], label='Time (s)', color='brown')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Time (seconds)')\n",
    "#     plt.title('Epoch Time')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     print(f\"Plots successfully generated from: {results_csv_path}\")\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# # Replace `your_model_path` with the actual path to `best.pt`\n",
    "# plot_training_metrics(best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:35:49.522671Z",
     "iopub.status.busy": "2024-12-18T11:35:49.521582Z",
     "iopub.status.idle": "2024-12-18T11:36:50.215908Z",
     "shell.execute_reply": "2024-12-18T11:36:50.214739Z",
     "shell.execute_reply.started": "2024-12-18T11:35:49.522602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 32 images.\n",
      "Processed batch of 8 images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "def load_test_images_in_batches(test_dir, target_size=(640, 640), batch_size=32):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses images from the test folder in batches.\n",
    "\n",
    "    Args:\n",
    "        test_dir (str): Directory containing test images.\n",
    "        target_size (tuple): Desired image size (width, height).\n",
    "        batch_size (int): Number of images to process per batch.\n",
    "\n",
    "    Yields:\n",
    "        tuple: Batch of images as a NumPy array and corresponding image IDs.\n",
    "    \"\"\"\n",
    "    image_files = [f for f in os.listdir(test_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "    for i in range(0, len(image_files), batch_size):\n",
    "        batch_files = image_files[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        batch_ids = []\n",
    "\n",
    "        for file in batch_files:\n",
    "            img_path = os.path.join(test_dir, file)\n",
    "            try:\n",
    "                # Load and preprocess the image\n",
    "                img = load_img(img_path, target_size=target_size)\n",
    "                img_array = img_to_array(img) / 255.0  # Novrmalize to [0, 1]\n",
    "                batch_images.append(img_array)\n",
    "                batch_ids.append(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "        yield np.array(batch_images), batch_ids\n",
    "\n",
    "# Example usage\n",
    "test_dir = 'test'\n",
    "for batch_images, batch_ids in load_test_images_in_batches(test_dir):\n",
    "    print(f\"Processed batch of {len(batch_images)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:37:45.883946Z",
     "iopub.status.busy": "2024-12-18T11:37:45.883147Z",
     "iopub.status.idle": "2024-12-18T11:37:45.897780Z",
     "shell.execute_reply": "2024-12-18T11:37:45.896478Z",
     "shell.execute_reply.started": "2024-12-18T11:37:45.883904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "def predict_yolo(model_path, test_dir, threshold=0.25, imgsz=640, device=None):\n",
    "    \"\"\"\n",
    "    Perform predictions using a YOLO model on test images.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the YOLO model file (e.g., 'best.pt').\n",
    "        test_dir (str): Path to the directory containing test images.\n",
    "        threshold (float): Confidence threshold for predictions (default 0.25).\n",
    "        imgsz (int): Image size for YOLO predictions (default 640).\n",
    "        device (str): Device to use for predictions (e.g., 'cuda', 'cpu', or None for auto-detection).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing 'image_id' and 'predicted_class'.\n",
    "    \"\"\"\n",
    "    # Load the YOLO model\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading model: {e}\")\n",
    "\n",
    "    # List all image files in the test directory\n",
    "    image_files = [f for f in os.listdir(test_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "    if not image_files:\n",
    "        raise ValueError(\"No image files found in the test directory.\")\n",
    "\n",
    "    predictions = []  # List to store results\n",
    "    errors = []  # List to log errors\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(test_dir, img_file)\n",
    "\n",
    "        try:\n",
    "            # Run prediction\n",
    "            results = model.predict(img_path, conf=threshold, imgsz=imgsz, device=device, verbose=False)\n",
    "\n",
    "            # Handle detections\n",
    "            if len(results[0].boxes) > 0:\n",
    "                # Extract confidence scores and classes\n",
    "                scores = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
    "                classes = results[0].boxes.cls.cpu().numpy().astype(int)  # Predicted classes\n",
    "\n",
    "                # Debugging confidence scores for verification\n",
    "                # print(f\"{img_file} - Confidences: {scores}\")\n",
    "\n",
    "                # Filter valid detections based on the confidence threshold\n",
    "                valid_indices = np.where(scores >= threshold)[0]\n",
    "\n",
    "                if len(valid_indices) > 0:\n",
    "                    # Pick the class with the highest confidence after filtering\n",
    "                    best_class = classes[valid_indices[np.argmax(scores[valid_indices])]]\n",
    "                else:\n",
    "                    best_class = 0  # Assign 0 if no valid detections (non-detection class)\n",
    "            else:\n",
    "                best_class = 0  # No detection → Class = 0\n",
    "\n",
    "            # Append results\n",
    "            predictions.append({\"image_id\": img_file, \"predicted_class\": best_class})\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log error and continue\n",
    "            errors.append(f\"Error processing {img_file}: {e}\")\n",
    "            predictions.append({\"image_id\": img_file, \"predicted_class\": 0})\n",
    "\n",
    "    # Log errors if any\n",
    "    if errors:\n",
    "        print(\"\\n--- Errors During Prediction ---\")\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "\n",
    "    # Return predictions as a DataFrame\n",
    "    return pd.DataFrame(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:37:54.532830Z",
     "iopub.status.busy": "2024-12-18T11:37:54.532333Z",
     "iopub.status.idle": "2024-12-18T11:37:55.022072Z",
     "shell.execute_reply": "2024-12-18T11:37:55.020580Z",
     "shell.execute_reply.started": "2024-12-18T11:37:54.532793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error loading model: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 21\u001b[0m, in \u001b[0;36mpredict_yolo\u001b[1;34m(model_path, test_dir, threshold, imgsz, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\tohru\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:16\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize YOLO model, switching to YOLOWorld if model filename contains '-world'.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-world\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstem \u001b[38;5;129;01mand\u001b[39;00m path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m}:  \u001b[38;5;66;03m# if YOLOWorld PyTorch model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tohru\\anaconda3\\Lib\\pathlib.py:1162\u001b[0m, in \u001b[0;36mPath.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1161\u001b[0m     warnings\u001b[38;5;241m.\u001b[39m_deprecated(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpathlib.PurePath(**kwargs)\u001b[39m\u001b[38;5;124m\"\u001b[39m, msg, remove\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m14\u001b[39m))\n\u001b[1;32m-> 1162\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tohru\\anaconda3\\Lib\\pathlib.py:373\u001b[0m, in \u001b[0;36mPurePath.__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument should be a str or an os.PathLike \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject where __fspath__ returns a str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    377\u001b[0m paths\u001b[38;5;241m.\u001b[39mappend(path)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model_path = '/kaggle/working/fall_detection3/weights/best.pt'  # YOLO model path\u001b[39;00m\n\u001b[0;32m      6\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Adjust sensitivity here\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m output_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8n/predictionswithyoelchan_scaler_10epochs_testsize30_.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m results_df\u001b[38;5;241m.\u001b[39mto_csv(output_csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[50], line 23\u001b[0m, in \u001b[0;36mpredict_yolo\u001b[1;34m(model_path, test_dir, threshold, imgsz, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLO(model_path)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# List all image files in the test directory\u001b[39;00m\n\u001b[0;32m     26\u001b[0m image_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(test_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n",
      "\u001b[1;31mValueError\u001b[0m: Error loading model: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "test_dir = 'test'  # Test images directory\n",
    "model_path = best_model_path  # YOLO model path\n",
    "# model_path = '/kaggle/working/fall_detection3/weights/best.pt'  # YOLO model path\n",
    "\n",
    "threshold = 0.5  # Adjust sensitivity here\n",
    "\n",
    "results_df = predict_yolo(model_path, test_dir, threshold=threshold)\n",
    "output_csv_path = 'yolov8n/predictionswithyoelchan_scaler_10epochs_testsize30_.csv'\n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Predictions saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-18T11:35:22.360893Z",
     "iopub.status.idle": "2024-12-18T11:35:22.361205Z",
     "shell.execute_reply": "2024-12-18T11:35:22.361070Z",
     "shell.execute_reply.started": "2024-12-18T11:35:22.361054Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files loaded: 0\n",
      "Total labels loaded: 0\n",
      "No files or labels were loaded. Please check the directory structure.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_labels_from_directory(base_dir):\n",
    "    data = []  # To store file paths\n",
    "    labels = []  # To store labels (1 for fall, 0 for nonfall)\n",
    "\n",
    "    # Recursively traverse directories\n",
    "    for root, dirs, files in os.walk(base_dir):  # os.walk handles nested directories\n",
    "        for category in dirs:  # Look at subdirectories\n",
    "            category_path = os.path.join(root, category)\n",
    "\n",
    "            # Assign label based on the folder name\n",
    "            if category.lower().startswith(\"fall_\"):\n",
    "                label = 1\n",
    "            elif category.lower().startswith(\"nonfall_\"):\n",
    "                label = 0\n",
    "            else:\n",
    "                # Skip folders that don't match the expected naming pattern\n",
    "                print(f\"Skipping unknown category: {category}\")\n",
    "                continue\n",
    "\n",
    "            # Debug: Print category and label\n",
    "            print(f\"Processing folder: {category}, Assigned Label: {label}\")\n",
    "\n",
    "            # Traverse files in this subdirectory\n",
    "            for file_name in os.listdir(category_path):\n",
    "                file_path = os.path.join(category_path, file_name)\n",
    "                \n",
    "                # Ensure it's a valid file (e.g., JPG)\n",
    "                if os.path.isfile(file_path) and file_name.lower().endswith(\".jpg\"):\n",
    "                    data.append(file_path)\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return data, labels\n",
    "# Example usage\n",
    "base_directory = '/kaggle/input/test-labeldiri'  # Replace with your directory path\n",
    "data, labels = load_labels_from_directory(base_directory)\n",
    "\n",
    "# Debug: Check if data was loaded\n",
    "print(f\"Total files loaded: {len(data)}\")\n",
    "print(f\"Total labels loaded: {len(labels)}\")\n",
    "\n",
    "# Only print a sample if data is available\n",
    "if data and labels:\n",
    "    for i in range(min(5, len(data))):  # Show up to 5 items\n",
    "        print(f\"File: {data[i]}, Label: {labels[i]}\")\n",
    "else:\n",
    "    print(\"No files or labels were loaded. Please check the directory structure.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-18T11:35:22.363387Z",
     "iopub.status.idle": "2024-12-18T11:35:22.363759Z",
     "shell.execute_reply": "2024-12-18T11:35:22.363570Z",
     "shell.execute_reply.started": "2024-12-18T11:35:22.363554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to /kaggle/working/file_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def export_to_csv(file_paths, labels, output_file):\n",
    "    \"\"\"Exports file paths and labels to a CSV file.\"\"\"\n",
    "    with open(output_file, mode='w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "        \n",
    "        # Write the header\n",
    "        csv_writer.writerow(['id', 'label'])\n",
    "        \n",
    "        # Write each file path and its corresponding label\n",
    "        for file_path, label in zip(file_paths, labels):\n",
    "            csv_writer.writerow([file_path, label])\n",
    "    \n",
    "    print(f\"Data exported to {output_file}\")\n",
    "\n",
    "# Specify the output CSV file path\n",
    "output_csv = '/kaggle/working/file_labels.csv'\n",
    "\n",
    "# Call the function to export data\n",
    "export_to_csv(data, labels, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-18T11:35:22.365118Z",
     "iopub.status.idle": "2024-12-18T11:35:22.365449Z",
     "shell.execute_reply": "2024-12-18T11:35:22.365305Z",
     "shell.execute_reply.started": "2024-12-18T11:35:22.365289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Function to load CSV data\n",
    "def load_csv(file_path):\n",
    "    \"\"\"Loads a CSV file and returns a dictionary with photo ID as key and label as value.\"\"\"\n",
    "    data_dict = {}\n",
    "    with open(file_path, mode='r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(csv_reader)  # Skip the header\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            # Check if the row contains a valid format\n",
    "            if len(row) != 2:\n",
    "                print(f\"Skipping invalid row: {row}\")\n",
    "                continue\n",
    "            \n",
    "            full_path_or_id, label = row\n",
    "            # Extract photo ID from the full path if necessary\n",
    "            photo_id = Path(full_path_or_id).name  # This ensures we only get the filename\n",
    "            data_dict[photo_id] = int(label)  # Convert label to integer\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# Function to calculate accuracy and log incorrect predictions\n",
    "def calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv):\n",
    "    \"\"\"\n",
    "    Compares the predicted labels to the ground truth labels using the photo IDs as keys.\n",
    "    Logs incorrect predictions for visualization.\n",
    "    \"\"\"\n",
    "    # Load both CSVs into dictionaries\n",
    "    predicted = load_csv(predicted_csv)\n",
    "    ground_truth = load_csv(ground_truth_csv)\n",
    "    \n",
    "    # Initialize counters\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    incorrect_predictions = []  # Store tuples of (photo_id, predicted_label, true_label)\n",
    "    \n",
    "    for photo_id, true_label in ground_truth.items():\n",
    "        # Check if the photo ID exists in the predicted data\n",
    "        if photo_id in predicted:\n",
    "            total += 1  # Increment total for every matched ID\n",
    "            if predicted[photo_id] == true_label:\n",
    "                correct += 1  # Increment correct if labels match\n",
    "            else:\n",
    "                incorrect_predictions.append((photo_id, predicted[photo_id], true_label))\n",
    "        else:\n",
    "            print(f\"Warning: Photo ID {photo_id} not found in predictions.\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy, correct, total, incorrect_predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "def visualize_incorrect_predictions_to_file(incorrect_predictions, image_dir, grid_size=5, resize_to=(100, 100), output_path=\"incorrect_predictions_grid.png\"):\n",
    "    num_images = min(len(incorrect_predictions), grid_size * grid_size*4)\n",
    "    rows = math.ceil(num_images / grid_size)\n",
    "    cols = grid_size\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, (photo_id, predicted_label, true_label) in enumerate(incorrect_predictions[:num_images]):\n",
    "        image_path = Path(image_dir) / photo_id\n",
    "        if not image_path.exists():\n",
    "            axes[idx].axis(\"off\")\n",
    "            continue\n",
    "        try:\n",
    "            img = Image.open(image_path).resize(resize_to, Image.Resampling.LANCZOS)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis(\"off\")\n",
    "            axes[idx].set_title(f\"Pred: {predicted_label}\\nTrue: {true_label}\", fontsize=8)\n",
    "        except Exception as e:\n",
    "            axes[idx].axis(\"off\")\n",
    "    for idx in range(num_images, len(axes)):\n",
    "        axes[idx].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout(pad=1.0)\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"Grid saved to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# File paths for comparison\n",
    "predicted_csv = output_csv_path  # Replace with your predicted CSV path\n",
    "ground_truth_csv = 'ground_truth.csv'  # Replace with your ground truth CSV path\n",
    "image_directory = 'test'  # Replace with the directory containing the images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-18T11:35:22.366435Z",
     "iopub.status.idle": "2024-12-18T11:35:22.366824Z",
     "shell.execute_reply": "2024-12-18T11:35:22.366627Z",
     "shell.execute_reply.started": "2024-12-18T11:35:22.366609Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.06% (1938/2152 correct predictions)\n",
      "Grid saved to incorrect_predictions_grid.png\n",
      "Visualizing 214 incorrect predictions...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x4000 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x2000 with 50 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy and log incorrect predictions\n",
    "accuracy, correct, total, incorrect_predictions = calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}% ({correct}/{total} correct predictions)\")\n",
    "# Save the visualization\n",
    "visualize_incorrect_predictions_to_file(incorrect_predictions, image_directory)\n",
    "# Visualize incorrect predictions\n",
    "# if incorrect_predictions:\n",
    "#     print(f\"Visualizing {len(incorrect_predictions)} incorrect predictions...\")\n",
    "#     visualize_incorrect_predictions(incorrect_predictions, image_directory)\n",
    "# else:\n",
    "#     print(\"No incorrect predictions to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-18T11:35:22.368048Z",
     "iopub.status.idle": "2024-12-18T11:35:22.368359Z",
     "shell.execute_reply": "2024-12-18T11:35:22.368223Z",
     "shell.execute_reply.started": "2024-12-18T11:35:22.368207Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.06% (1938/2152 correct predictions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    Generate and plot a confusion matrix with a heatmap.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv):\n",
    "    \"\"\"\n",
    "    Compares the predicted labels to the ground truth labels and calculates accuracy.\n",
    "    Also logs incorrect predictions.\n",
    "    \"\"\"\n",
    "    # Load CSVs into dictionaries\n",
    "    predicted = load_csv(predicted_csv)\n",
    "    ground_truth = load_csv(ground_truth_csv)\n",
    "    \n",
    "    # Initialize counters and lists for incorrect predictions\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    incorrect_predictions = []\n",
    "    \n",
    "    y_true = []  # True labels\n",
    "    y_pred = []  # Predicted labels\n",
    "    \n",
    "    for photo_id, true_label in ground_truth.items():\n",
    "        # Check if the photo ID exists in the predicted data\n",
    "        if photo_id in predicted:\n",
    "            total += 1  # Increment total for every matched ID\n",
    "            predicted_label = predicted[photo_id]\n",
    "            y_true.append(true_label)\n",
    "            y_pred.append(predicted_label)\n",
    "            \n",
    "            if predicted_label == true_label:\n",
    "                correct += 1  # Increment correct if labels match\n",
    "            else:\n",
    "                # Log the incorrect prediction\n",
    "                incorrect_predictions.append((photo_id, predicted_label, true_label))\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy, correct, total, incorrect_predictions, y_true, y_pred\n",
    "\n",
    "# Example usage\n",
    "predicted_csv = output_csv_path  # Replace with your predicted CSV path\n",
    "ground_truth_csv = 'ground_truth.csv'  # Replace with your ground truth CSV path\n",
    "\n",
    "# Get accuracy and incorrect predictions\n",
    "accuracy, correct, total, incorrect_predictions, y_true, y_pred = calculate_accuracy_and_log_incorrect(predicted_csv, ground_truth_csv)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}% ({correct}/{total} correct predictions)\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "labels = [0, 1]  # Change if you have more classes\n",
    "plot_confusion_matrix(y_true, y_pred, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6283444,
     "sourceId": 10173406,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6298432,
     "sourceId": 10193603,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6301602,
     "sourceId": 10198298,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6303304,
     "sourceId": 10200494,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6304343,
     "sourceId": 10201824,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6305780,
     "sourceId": 10203994,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6308929,
     "sourceId": 10208241,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
